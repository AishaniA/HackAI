import os
import pymupdf  # PyMuPDF
import pdfplumber
import pandas as pd
import sqlite3
from PIL import Image
from io import BytesIO
from langchain.document_loaders import PyMuPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI
from langchain.tools import Tool
from langchain.agents import initialize_agent, AgentType
import openai

# === Set your OpenAI key ===
os.environ["OPENAI_API_KEY"] = ""  # Replace with your key

# === Setup paths ===
OUTPUT_DIR = "/Users/succhaygadhar/Downloads/output"
TEXT_PATH = os.path.join(OUTPUT_DIR, "text_chunks.txt")
TABLES_DIR = os.path.join(OUTPUT_DIR, "tables")
IMAGES_DIR = os.path.join(OUTPUT_DIR, "images")
DB_PATH = os.path.join(OUTPUT_DIR, "financials.db")
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(TABLES_DIR, exist_ok=True)
os.makedirs(IMAGES_DIR, exist_ok=True)

# === Extract text from PDF ===
def extract_text_chunks(pdf_path, chunk_size=500):
    doc = pymupdf.open(pdf_path)
    text_chunks = []
    with open(TEXT_PATH, "w", encoding="utf-8") as f:
        for page in doc:
            text = page.get_text()
            paragraphs = text.split("\n\n")
            for para in paragraphs:
                if len(para.strip()) > 0:
                    for i in range(0, len(para), chunk_size):
                        chunk = para[i:i + chunk_size]
                        text_chunks.append(chunk)
                        f.write(chunk + "\n\n")
    doc.close()
    return text_chunks

# === Extract tables and load into SQLite ===
def extract_tables_to_db(pdf_path, db_path):
    conn = sqlite3.connect(db_path)
    tables = []
    with pdfplumber.open(pdf_path) as pdf:
        for page_num, page in enumerate(pdf.pages):
            extracted_tables = page.extract_tables()
            for i, table in enumerate(extracted_tables):
                if not table or len(table) < 2:
                    continue  # skip empty or invalid tables

                df = pd.DataFrame(table[1:], columns=table[0])

                # Fix empty or invalid column names
                df.columns = [
                    f"col_{j}" if (not col or str(col).strip() == '') else str(col).strip()
                    for j, col in enumerate(df.columns)
                ]

                table_name = f"table_page{page_num+1}_{i+1}"
                df.to_sql(table_name, conn, if_exists="replace", index=False)
                df.to_csv(os.path.join(TABLES_DIR, f"{table_name}.csv"), index=False)
                tables.append((table_name, df))
    conn.commit()
    conn.close()
    return tables

# === Extract images ===
def extract_images(pdf_path):
    doc = pymupdf.open(pdf_path)
    img_count = 0
    for i in range(len(doc)):
        for img_index, img in enumerate(doc.get_page_images(i)):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            image = Image.open(BytesIO(image_bytes))
            img_path = os.path.join(IMAGES_DIR, f"page{i+1}_img{img_index+1}.png")
            image.save(img_path)
            img_count += 1
    doc.close()
    return img_count

# === Parse PDF and prepare everything ===
def parse_pdf(pdf_path):
    print("Extracting text...")
    text_chunks = extract_text_chunks(pdf_path)

    print("Extracting tables...")
    tables = extract_tables_to_db(pdf_path, DB_PATH)

    print("Extracting images...")
    num_images = extract_images(pdf_path)

    return {
        "text_chunks": text_chunks,
        "tables": tables,
        "num_images": num_images,
        "db_path": DB_PATH
    }

# === Setup LangChain Retrieval QA ===
def setup_retriever(pdf_path):
    loader = PyMuPDFLoader(pdf_path)
    documents = loader.load()
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    chunks = splitter.split_documents(documents)
    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents(chunks, embeddings)
    vectorstore.save_local("faiss_index")
    retriever = vectorstore.as_retriever()
    return RetrievalQA.from_chain_type(llm=ChatOpenAI(model="gpt-4"), retriever=retriever, return_source_documents=True)

# === SQL Execution Tool ===
def run_sql_query(query):
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.execute(query)
        rows = cursor.fetchall()
        return str(rows)
    except Exception as e:
        return f"SQL Error: {e}"

# === Main Agent Setup ===
def setup_agent(qa_chain):
    doc_qa_tool = Tool(
    name="PDF_QA_Tool",
    func=lambda q: qa_chain.invoke({"query": q})["result"],
    description="Use this to answer questions about the annual report PDF."
    )

    sql_tool = Tool(
        name="SQL_Tool",
        func=run_sql_query,
        description="Useful for querying tabular data from the financials database using SQL."
    )
    llm = ChatOpenAI(temperature=0, model="gpt-4")
    return initialize_agent(tools=[doc_qa_tool, sql_tool], llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)

# === Example Run ===
if __name__ == "__main__":
    pdf_path = "/Users/succhaygadhar/Downloads/ltimindtree_annual_report.pdf"  # Replace with your file
    parse_pdf(pdf_path)
    qa_chain = setup_retriever(pdf_path)
    agent = setup_agent(qa_chain)

    while True:
        query = input("\nðŸ’¬ Ask a question (or type 'exit'): ")
        if query.lower() == "exit":
            break
        response = agent.run(query)
        print("\nðŸ§  Response:", response)